
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Recurrent approaches: RNNs, LSTMs, and GRUs &#8212; Tempo, Beat and Downbeat Estimation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Convolutional approaches: CNNs, TCNs" href="convolutional.html" />
    <link rel="prev" title="Perspectives" href="../ch2_basics/perspectives.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Tempo, Beat and Downbeat Estimation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Tempo, Beat, and Downbeat Estimation
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch1_intro/tutorial_structure.html">
   Tutorial structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch1_intro/tutorial_scope.html">
   Tutorial scope
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch1_intro/resources.html">
   Resources and relevant projects
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Basics of tempo, beat, and downbeat
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch2_basics/definition.html">
   Definition by sound example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch2_basics/annotation.html">
   How do we annotate?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch2_basics/baseline.html">
   Baseline Approach
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch2_basics/evaluate.html">
   How do we evaluate?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch2_basics/perspectives.html">
   Perspectives
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Going deep: theoretical underpinnings
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Recurrent approaches: RNNs, LSTMs, and GRUs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="convolutional.html">
   Convolutional approaches: CNNs, TCNs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="design_decisions.html">
   Design decisions for tempo, beat, and downbeat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="table.html">
   Reference works
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Going deeper: pracital examples
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/loading_a_dataset.html">
   Loading a dataset with mir-data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/encoding_targets.html">
   Encoding the target representations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/creating_splits.html">
   Creating splits for the dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/building_tcn_models.html">
   Building individual TCN models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/training_tcns.html">
   Training the TCNs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/model_prediction.html">
   Model prediction and inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/evaluation.html">
   Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/multitask.html">
   Multi-task formulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_going_deeper/fine_tuning.html">
   Fine-tuning
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Discussion and conclusions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch5_discussion/recap.html">
   Recap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch5_discussion/real_world_limitations.html">
   Real world limitations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch5_discussion/open_challenges.html">
   Open challenges
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch6_resources/references.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch6_resources/acknowledgments.html">
   Acknowledgments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch6_resources/authors.html">
   About the Authors
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch3_going_deep/recurrent.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/magdalenafuentes/rhythm_tutorial"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/magdalenafuentes/rhythm_tutorial/issues/new?title=Issue%20on%20page%20%2Fch3_going_deep/recurrent.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-bit-of-context">
   A bit of context
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multi-layer-perceptrons">
   Multi-layer perceptrons
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#recurrent-networks">
   Recurrent networks
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="recurrent-approaches-rnns-lstms-and-grus">
<span id="dnns"></span><h1>Recurrent approaches: RNNs, LSTMs, and GRUs<a class="headerlink" href="#recurrent-approaches-rnns-lstms-and-grus" title="Permalink to this headline">¶</a></h1>
<p>The goal of this section is to provide the theoretical underpinnings of DNN models commonly used for tempo, beat and downbeat tracking, to build an understanding of why these models work well in these tasks and what are their limitations. Here we discuss the main concepts and definitions,
but for those interested in reading more about the use of DNNs in audio processing and MIR related tasks,  we suggest them to take a look at works like McFee <span id="id1">[<a class="reference internal" href="../ch6_resources/references.html#id225">McF18</a>]</span>, Purwins et al. <span id="id2">[<a class="reference internal" href="../ch6_resources/references.html#id227">PLV+19</a>]</span> and Choi et al. <span id="id3">[<a class="reference internal" href="../ch6_resources/references.html#id221">CFCS17</a>]</span>.</p>
<p><strong>Sebastian do you have further suggestions for resources about DNNs for audio/MIR here</strong>?</p>
<div class="section" id="a-bit-of-context">
<h2>A bit of context<a class="headerlink" href="#a-bit-of-context" title="Permalink to this headline">¶</a></h2>
<p>Motivated by the huge success of deep neural networks (DNNs) in Computer Vision, and due to recent advances that allow for faster training and scalability, DNNs have been widely used in many other domains, in particular in audio related tasks <span id="id4">[<a class="reference internal" href="../ch6_resources/references.html#id220">GBC16</a>]</span>.
The inclusion of these models in MIR tasks has meant a considerable improvement in the performance of automatic systems, in particular tempo, beat and downbeat tracking ones, as can be seen from the MIREX campaigns <span id="id5">[<a class="reference internal" href="../ch6_resources/references.html#id230">JLL19</a>]</span>.
Moreover, the use of deep learning models presents other advantages over traditional machine learning methods used in MIR, i.e. they are flexible and adaptable across tasks. As an example, convolutional neural network based models from Computer Vision were adapted for
onset detection <span id="id6">[<a class="reference internal" href="../ch6_resources/references.html#id195">SchluterBock14</a>]</span>, and then for  segment boundary detection <span id="id7">[<a class="reference internal" href="../ch6_resources/references.html#id137">USchluterG14</a>]</span>. Furthermore, DNNs reduce —or allow to remove completely— the stage of hand-crafted feature design, by including the feature learning as part of the learning
process.</p>
<p>However, the use of supervised deep learning models presents some disadvantages, one of the main ones being their dependence on annotated data. Annotated data is an important bottleneck in MIR especially due to copyright issues, and because annotating a musical piece requires
expert knowledge and is thus expensive. Besides, solutions obtained in a data-driven fashion suffer from bias depending on the dataset used, a problem that also occurs in other learning-based approaches. Besides, deep-learning based methods are usually less interpretable than
signal processing methods, making it a bit hard to predict the type of mistakes a DNN would do when presented with e.g. unseen music tracks or genres.</p>
<p>In general terms, a deep neural network consists of a composition of non-linear functions that acts as a function approximator <span class="math notranslate nohighlight">\(F_\omega: \mathbf{X} \rightarrow \mathbf{Y}\)</span>, for given input and output data <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>.
The network is parametrized by its weights <span class="math notranslate nohighlight">\(\omega\)</span>, whose values are optimized so the estimated output <span class="math notranslate nohighlight">\(\hat{\mathbf{Y}}=F_\omega (\mathbf{X})\)</span> approximates the desired output <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> given an input <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>.</p>
</div>
<div class="section" id="multi-layer-perceptrons">
<h2>Multi-layer perceptrons<a class="headerlink" href="#multi-layer-perceptrons" title="Permalink to this headline">¶</a></h2>
<p>Multi-layer perceptrons (MLPs) are the simple and basic modules of DNNs. They are also known as <em>fully-connected layers</em> or <em>dense layers</em>, and consist of a sequence of layers, each defined by an affine transformation composed with a non-linearity:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} = f(\mathbf{W}^T \mathbf{x} + \mathbf{b}),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^{d_{in}}\)</span> is the input, <span class="math notranslate nohighlight">\(\mathbf{y} \in \mathbb{R}^{d_{out}}\)</span> is the output, <span class="math notranslate nohighlight">\(\mathbf{b} \in \mathbb{R}^{d_{out}}\)</span> is called the <em>bias vector</em> and <span class="math notranslate nohighlight">\(\mathbf{W} \in \mathbb{R}^{d_{in} \times d_{out}}\)</span> is the weight matrix. <span class="math notranslate nohighlight">\(f()\)</span> is a non-linear activation function, which allows the model to learn non-linear
representations. Note that for multi-dimensional inputs, e.g. <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{d_1 \times d_2}\)</span>, the  input is flattened so <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^{d}\)</span> with <span class="math notranslate nohighlight">\(d = d_1 \times d_2\)</span>. These layers are usually used to map the input to another space where hopefully the problem (e.g. classification or regression) can be solved more easily. However, by definition, this type of layer is not shift or scale invariant,
meaning that when using this type of network for audio tasks, any small temporal or frequency shift needs dedicated parameters to be modelled, becoming very expensive and inconvenient when it comes to modelling music.</p>
<p>MLPs have been mainly used in early works before convolutional neural networks (CNNs) and recurrent neural networks (RNNs) became popular <span id="id8">[<a class="reference internal" href="../ch6_resources/references.html#id221">CFCS17</a>]</span>, and are now used in combination with those architectures, usually as the last layers of a model to map high dimensional intermediate representations
to the output space (e.g. classes), as discussed below.</p>
</div>
<div class="section" id="recurrent-networks">
<h2>Recurrent networks<a class="headerlink" href="#recurrent-networks" title="Permalink to this headline">¶</a></h2>
<p>Unlike CNNs which are effective at modelling fixed-length local interactions, <em>recurrent neural networks</em> (RNNs) are good in modelling variable-length long-term interactions. RNNs exploit recurrent connections since they are formulated as <span id="id9">[<a class="reference internal" href="../ch6_resources/references.html#id220">GBC16</a>]</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
       \mathbf{y}_t = f_{y}(\mathbf{W}_y\:\mathbf{h}_t + \mathbf{b}_y), \label{eq:rnn_def_1}\\
        \mathbf{h}_t = f_{h}(\mathbf{W}_h\:\mathbf{x}_t + \mathbf{U}\: \mathbf{h}_{t-1} + \mathbf{b}_h),\label{eq:rnn_def_2}
\end{align}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{h}_t\)</span> is a hidden <em>state vector</em> that stores information at time <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(f_y\)</span> and <span class="math notranslate nohighlight">\(f_h\)</span> are the non-linearities of the output and hidden state respectively, and <span class="math notranslate nohighlight">\(\mathbf{W}_y, \mathbf{W}_h\)</span> and <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> are matrices of trainable weights.
An RNN integrates information over time up to time step <span class="math notranslate nohighlight">\(t\)</span> to estimate the state vector <span class="math notranslate nohighlight">\(\mathbf{h}_t\)</span>, being suitable to model sequential data.
Note that learning the weights <span class="math notranslate nohighlight">\(\mathbf{W}_y, \mathbf{W}_h\)</span> and <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> in a RNN is challenging given the dependency of the gradient on the entire state sequence <span id="id10">[<a class="reference internal" href="../ch6_resources/references.html#id225">McF18</a>]</span>. In practice, <em>back-propagation through time</em> is used
<span id="id11">[<a class="reference internal" href="../ch6_resources/references.html#id148">W+90</a>]</span>, which consists in unrolling Equation \ref{eq:rnn_def_2} up to <span class="math notranslate nohighlight">\(k\)</span> time steps and applying standard back propagation. Given the accumulative effect of applying <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> when unrolling Equation  \ref{eq:rnn_def_2}, the gradient values tend to either vanish or explode if <span class="math notranslate nohighlight">\(k\)</span> is too big, a problem known as the \textit{vanishing and exploding gradient problem}. For that reason, in practice the value of <span class="math notranslate nohighlight">\(k\)</span> is limited to account for relatively short sequences.</p>
<p>The most commonly used variations of RNNs, that were designed to mitigate the vanishing/exploding problem of the gradient, include the addition of \textit{gates} that control the flow of information through the network. The most popular ones in MIR applications are \textit{long-short memory units} (LSTMs) \cite{hochreiter1997long} and \textit{gated recurrent units} (GRUs) \cite{Cho2014}. We will focus here on GRUs, which we use in our experiments in the following chapters, and mention LSTMs only to draw differences between the two neural networks.</p>
<p>\subsubsection{Gated recurrent units}</p>
<p>In a GRU layer, the \textit{gate} variables <span class="math notranslate nohighlight">\(\mathbf{r}_t\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u}_t\)</span> —named as \textit{reset} and \textit{update} vectors— control the updates to the state vector <span class="math notranslate nohighlight">\(\mathbf{h}_t\)</span>, which is a combination of the previous state <span class="math notranslate nohighlight">\(\mathbf{h}_{t-1}\)</span> and a proposed next state <span class="math notranslate nohighlight">\(\hat{\mathbf{h}}_t\)</span>. The equations that rule these updates are given by:</p>
<p>\begin{subequations}\label{eq:gru_def}
\begin{align}
\mathbf{r}_t = f_g(\mathbf{W}_r \mathbf{x}_t + \mathbf{U}<em>r \mathbf{h}</em>{t-1} + \mathbf{b}_r), \label{eq:gru_def_1}\
\mathbf{u}_t = f_g(\mathbf{W}_u \mathbf{x}_t + \mathbf{U}<em>u \mathbf{h}</em>{t-1} + \mathbf{b}_u),\label{eq:gru_def_2}\
\hat{\mathbf{h}}_t = f_h(\mathbf{W}_h \mathbf{x}_t + \mathbf{U}_h (\mathbf{r}<em>t\odot \mathbf{h}</em>{t-1}) + \mathbf{b}_h), \label{eq:gru_def_3}\
\mathbf{h}_t = \mathbf{u}<em>t\odot \mathbf{h}</em>{t-1} + (1-\mathbf{u}_t)\odot \hat{\mathbf{h}}_t;\label{eq:gru_def_4}
\end{align}
\end{subequations}</p>
<p>\noindent
<span class="math notranslate nohighlight">\(\odot\)</span> indicates the element-wise Hadamard product, <span class="math notranslate nohighlight">\(f_g\)</span> is the activation applied to the reset and update vectors, and <span class="math notranslate nohighlight">\(f_h\)</span> is the output activation. <span class="math notranslate nohighlight">\(\mathbf{W}_r, \mathbf{W}_u, \mathbf{W}_h \in \mathbb{R}^{d_{i-1}\times d_i}\)</span> are the input weights, <span class="math notranslate nohighlight">\(\mathbf{U}_r, \mathbf{U}_u, \mathbf{U}_h \in \mathbb{R}^{d_{i}\times d_i}\)</span> are the recurrent weights and <span class="math notranslate nohighlight">\(\mathbf{b}_r, \mathbf{b}_u, \mathbf{b}_h \in \mathbb{R}^{d_{i}}\)</span> are the biases. The activation functions <span class="math notranslate nohighlight">\(f_g\)</span> and <span class="math notranslate nohighlight">\(f_h\)</span> are typically sigmoid and tanh, since saturating functions help to avoid exploding gradients in recurrent networks.</p>
<p>The GRU operates as follows: when <span class="math notranslate nohighlight">\(\mathbf{u}_t\)</span> is close to 1, the previous observation <span class="math notranslate nohighlight">\(\mathbf{h}_{t-1}\)</span> dominates in Equation \ref{eq:gru_def_4}. When <span class="math notranslate nohighlight">\(\mathbf{u}_t\)</span> gets close to 0, depending on the value of <span class="math notranslate nohighlight">\(\mathbf{r}_t\)</span>, either a new state is updated with the standard recurrent equation by <span class="math notranslate nohighlight">\(\hat{\mathbf{h}}_t = f(\mathbf{W}_h \mathbf{x}_t + \mathbf{v}_h \mathbf{h}_{t-1} + \mathbf{b}_h)\)</span>, if <span class="math notranslate nohighlight">\(\mathbf{r}_t=1\)</span>, or the state is ``reset’’ as if the <span class="math notranslate nohighlight">\(\mathbf{x}_t\)</span> was the first observation in the sequence by <span class="math notranslate nohighlight">\(\hat{\mathbf{h}}_t = f(\mathbf{W}_h \mathbf{x}_t + \mathbf{b}_h)\)</span>.\
The reset variables allow GRUs to successfully model long-term interactions, and perform comparably to LSTMs, but GRUs are simpler since LSTMs have three gate vectors and one extra \textit{memory} gate. Empirical studies show that both networks perform comparably  while GRUs are faster to train \cite{greff2016lstm, jozefowicz2015empirical}, so in this dissertation we will use GRUs for the study of long-term dependencies over time.</p>
<p>\subsubsection{Bi-directional models}</p>
<p>GRUs and RNNs in general are designed to integrate information in one direction, e.g. in an audio application they integrate information forward in time. However, it can be beneficial to integrate information in both directions, and so has been the case for neural networks in audio applications such as beat tracking \cite{bock2011enhanced} or environmental sound detection \cite{parascandolo2016recurrent}. A bi-directional recurrent neural network (Bi-RNN) \cite{schuster1997bidirectional} in the context of audio consists of two RNNs running in opposite time directions with their hidden vectors <span class="math notranslate nohighlight">\(\mathbf{h}_t ^f\)</span> and <span class="math notranslate nohighlight">\(\mathbf{h}_t ^b\)</span> being concatenated, so the output <span class="math notranslate nohighlight">\(h_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> has information about the entire sequence. Unless the application is online, Bi-RNNs are usually preferred due to better performance \cite{McFee2018}.</p>
<p>\subsection{Hybrid architectures}
\label{ssec:hybrid_dnns}</p>
<p>As mentioned before, MLPs are now usually being used in combination with CNNs, which are able to overcome the lack of shift and scale invariance MLPs suffer. At the same time, MLPs offer a simple alternative for mapping representations from a big-dimensional space to a smaller one, suitable for classification problems.</p>
<p>Finally, hybrid architectures that integrate convolutional and recurrent networks have recently become popular and have proven to be effective in audio applications, especially in MIR \cite{sigtia2016end, mcfee2017_structured}. They integrate local feature learning with global feature integration, a playground between time scales that is in particular interesting in the scope of this dissertation. In the following chapters, and considering what was exposed in this section, we explore hybrid architectures for the task of rhythm analysis.</p>
<p>\subsection{Learning and optimization}</p>
<p>To optimize the parameters <span class="math notranslate nohighlight">\(\omega\)</span>, a variant of gradient descent is usually exploited. A \textit{loss function} <span class="math notranslate nohighlight">\(J(\omega)\)</span> measures the difference between the predicted and desired outputs <span class="math notranslate nohighlight">\(\hat{\mathbf{Y}}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>, so the main idea behind the optimization process is to iteratively update the weights <span class="math notranslate nohighlight">\(\omega\)</span> so the loss function decreases, that is:</p>
<p>\begin{equation}\label{eq:gradient_descent}
\omega \leftarrow \omega - \eta \nabla_\omega J(\omega)
\end{equation}</p>
<p>\noindent
Where <span class="math notranslate nohighlight">\(\eta\)</span> is the \textit{learning rate} which controls how much to update the values of <span class="math notranslate nohighlight">\(\omega\)</span> at each iteration. Because the DNN consists of a composition of functions, the gradient of <span class="math notranslate nohighlight">\(J(\omega)\)</span>, <span class="math notranslate nohighlight">\(\nabla \omega J(\omega)\)</span>, is obtained via the chain rule, a process known as \textit{back propagation}. In the last four years, many software packages that implement automatic differentiation tools and various versions of gradient descent were released, \cite{chollet2015keras, tensorflow2015, theano2016}, reducing considerably the time needed for the implementation of such models.</p>
<p>Since computing the gradient over a large training set is very expensive both in memory and computational complexity, a widely adopted variant of gradient descent is \textit{Stochastic Gradient Descent} (SGD) \cite{bottou1991stochastic}, which approximates the gradient at each step on a mini-batch of training samples, <span class="math notranslate nohighlight">\(B\)</span>, considerably smaller than the training set. There are other variants of SGD such as \textit{momentum} methods or \textit{adaptive update} schemes that accelerate convergence dramatically, by re-using information of previous gradients (momentum) and reducing the dependence on <span class="math notranslate nohighlight">\(\eta\)</span>. From 2017, the most popular method for optimizing DNNs has been the adaptive method ADAM \cite{Adam}, which is the one we use in our work.</p>
<p>Another common practice in the optimization of DNNs is to use \textit{early stopping} as regularization \cite{sjoberg1995overtraining}, which means to stop training if the training –or validation– loss is not improving after a certain amount of iterations. Finally, \textit{batch normalization} (BN) \cite{batchnorm} is widely used in practice as well, and consists of scaling the data by estimating its statistics during training, which usually leads to better performance and faster convergence.</p>
<p>\subsection{Activation functions}</p>
<p>The expressive power of DNNs is in great extent due to the use of non-linearities <span class="math notranslate nohighlight">\(f()\)</span> in the model. The type of non-linearity used depends on whether it is an internal layer or the output layer. Many different options have been explored in the literature for intermediate-layer non-linearities —usually named \textit{transfer functions}, the two main groups being saturating or non-saturating functions (e.g. \textit{tanh} or \textit{sigmoid} for saturated, because they saturate in 0 and 1, and \textit{rectified linear units} (ReLUs) \cite{nair2010rectified} for non-saturating ones). Usually non-saturating activations are preferred in practice for being simpler to train and increasing training speed \cite{McFee2018}.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch3_going_deep"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="../ch2_basics/perspectives.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Perspectives</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="convolutional.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Convolutional approaches: CNNs, TCNs</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Matthew E. P. Davies, Sebastian Bock, Magdalena Fuentes<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>